{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "detailed-charity",
   "metadata": {},
   "source": [
    "# Using `tables_io.read`, `tables_io.write` and `tables_io.convert`\n",
    "\n",
    "These functions can be used to read and write single tables and to convert them to different formats\n",
    "\n",
    "The Tables can be in any of the formats that `tables_io` supports, see more on that in the notebook below.\n",
    "\n",
    "Let's have a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import numpy as np\n",
    "import tables_io\n",
    "from tables_io.testUtils import make_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make several tables and grab one\n",
    "tables = make_test_data()\n",
    "data = tables['data']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = tables_io.convert(data, tables_io.types.NUMPY_DICT)\n",
    "data_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd = tables_io.convert(data, tables_io.types.PD_DATAFRAME)\n",
    "data_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-steering",
   "metadata": {},
   "source": [
    "# File IO with `tables_io`\n",
    "\n",
    "We can write tables into several different formats.  These include:\n",
    "\n",
    "1. fits:  Writing `astropy.table.Table` objects to FITS files (with the suffix 'fits')\n",
    "2. hf5: Writing `astropy.table.Table` objects to HDF5 files (with the suffix 'hf5')\n",
    "3. hfd5: Writing `numpy.array` objects to HDF5 files (with the suffix 'hdf5')\n",
    "4. h5: Writing `pandas.DataFrame` objects to HDF5 files (with the suffix 'h5')\n",
    "5. pq: Writing `pandas.DataFrame` objects to parquet files (with the suffix 'pq')\n",
    "\n",
    "Also, each table type has a 'native' format that we use as a default.  Setting the `fmt` to `None` in function calls will typically use the 'native' format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fmts = list(tables_io.types.FILE_FORMAT_SUFFIXS.keys()) + [None]\n",
    "print(all_fmts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-rebate",
   "metadata": {},
   "source": [
    "# Ok let's write the data to different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fmt in all_fmts:\n",
    "    if fmt is None:\n",
    "        basename = 'test_single_native'\n",
    "    else:\n",
    "        basename = 'test_single_out'\n",
    "    print(\"Writing to %s using format %s\" % (basename, fmt))\n",
    "    try:\n",
    "        os.unlink('%s.%s' % (basename, fmt))\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        tables_io.write(data, basename, fmt)\n",
    "    except ImportError as msg:\n",
    "        print(\"Skipping format %s because %s\" % (fmt, msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls test_single_*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-institute",
   "metadata": {},
   "source": [
    "# Ok, now let's read things back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r_fits = tables_io.read(\"test_single_out.fits\")\n",
    "data_r_fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-favorite",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r_hdf5 = tables_io.read(\"test_single_out.hdf5\")\n",
    "data_r_hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r_hf5 = tables_io.read(\"test_single_out.hf5\")\n",
    "data_r_hf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r_pq = tables_io.read(\"test_single_out.pq\", keys=[''])\n",
    "data_r_pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r_h5 = tables_io.read(\"test_single_out.h5\")\n",
    "data_r_h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_native = tables_io.read(\"test_single_native.hf5\")\n",
    "data_native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-tunnel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-africa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
